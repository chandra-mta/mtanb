{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# To use tensorflow follow instructions here: https://www.tensorflow.org/install/pip\n",
    "# follow instructions related to creating a virtual environment with conda which can be the same \n",
    "# environment as ska3 here: https://github.com/sot/skare3/wiki/Ska3-runtime-environment-for-users\n",
    "# ska is also needed\n",
    "#########################################\n",
    "# if any of these imports fail something is wrong with the environment\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Ska.engarchive import fetch\n",
    "import Chandra.Time\n",
    "from kadi import events\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "from Quaternion import Quat\n",
    "import demo_functions as dmf\n",
    "\n",
    "def quatty(quarts):\n",
    "    quat = Quat(quarts)\n",
    "    return ([quat.roll, quat.yaw])\n",
    "\n",
    "# This function takes the aoattqt data and the msid data as an MSIDset\n",
    "# and returns the combined dataset\n",
    "def get_all_data(msid_data, quat_data, pitch_data):\n",
    "    t1998 = 883612730.816\n",
    "    from mica.quaternion import normalize\n",
    "    quat_vals = normalize(np.vstack([quat_data[\"{}{}\".format('AOATTQT',i)].vals for i in [1,2,3,4]]).transpose())\n",
    "    #quat_vals = pd.DataFrame(x)\n",
    "    start_time = timeit.default_timer()\n",
    "    quat_vect_new = dmf.get_quaternion(quat_vals)\n",
    "    print (\"got new quat vals: \", timeit.default_timer() - start_time)\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    #quat_vect = np.apply_along_axis(quatty, 1, quat_vals)\n",
    "    #print (\"quat vect shape: \", quat_vect.shape)\n",
    "    print (\"got quat vals: \", timeit.default_timer() - start_time)\n",
    "    quat_times = data['AOATTQT1'].times\n",
    "    print (quat_times.shape)\n",
    "    #roll_v, yaw_v = quat_vect[:,0], quat_vect[:,1]\n",
    "    new_roll, new_yaw = quat_vect_new[2] , quat_vect_new[3]\n",
    "    #print (\"equalities: \", np.all((roll_v ==roll_v==new_roll), np.all(yaw_v==new_yaw)))\n",
    "    roll_df = pd.DataFrame({'times': quat_times, 'vals': new_roll})\n",
    "    yaw_df = pd.DataFrame({'times':quat_times, 'vals': new_yaw})\n",
    "    msid_data_tme = msid_data.times\n",
    "    msid_times = np.array(pd.to_datetime(ne.evaluate('msid_data_tme + t1998'), \n",
    "                                         unit = 's', box = False), dtype = 'datetime64[s]')\n",
    "    combined_dict = {'msid_times': msid_times, \n",
    "                     'raw_times': msid_data_tme,\n",
    "                    'msid_vals': msid_data.vals,\n",
    "                    'pitch': dmf.select_intervals(msid_data, pitch_data), \n",
    "                    'roll': dmf.select_intervals(msid_data,roll_df),\n",
    "                    'yaw': dmf.select_intervals(msid_data, yaw_df)}\n",
    "    return (combined_dict, quat_vect_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file already exists, will not pull\n",
      "Here are the years we will pull data for:  []\n",
      "WARNING: COLLATING ONE YEAR OF DATA TAKES AROUND 15 MINUTES\n"
     ]
    }
   ],
   "source": [
    "msid_value = 'OOBTHR39'\n",
    "# ['OOBTHR41','AIRU1G2I','AIRU1G1I','AIRU2G1I','AIRU2G2I','OOBTHR08', 'OOBTHR39','OOBTHR41','OOBTHR06','OOBTHR08','OOBTHR09','OOBTHR18','OOBTHR19','OOBTHR25','OOBTHR26','OOBTHR40','OOBTHR51', '2CBLUAST','2CBHUAST', 'DP_PITCH']\n",
    "\n",
    "###### STEP 2: SINGLE OR COMPARE MULTIPLE YEARS ######\n",
    "train_years = [2014,2015,2016,2017,2018]\n",
    "test_year = 2019\n",
    "\n",
    "need_to_pull = []\n",
    "import pickle , os\n",
    "file_format = '{}_{}_msid_data.pkl'\n",
    "test_msid_file = file_format.format(msid_value, test_year)\n",
    "\n",
    "###### STEP 3: PULL + COLLATE DATA ######\n",
    "# 'collate' means calculate and assign a pitch, roll, yaw value to each time period\n",
    "# this is done using sad_common_functions can look there for more ingo\n",
    "#########################################\n",
    "\n",
    "#check if we already have the data for the test year\n",
    "if os.path.isfile(test_msid_file):\n",
    "    print('Test file already exists, will not pull')\n",
    "else:\n",
    "    need_to_pull += [test_year]\n",
    "\n",
    "#check if we have data for all the training years\n",
    "for t_year in train_years:\n",
    "    train_file = file_format.format(msid_value, t_year)\n",
    "    if not os.path.isfile(train_file):\n",
    "        need_to_pull += [t_year]\n",
    "print(\"Here are the years we will pull data for: \", need_to_pull)\n",
    "print(\"WARNING: COLLATING ONE YEAR OF DATA TAKES AROUND 15 MINUTES\")\n",
    "\n",
    "#if we don't have data for training years we pull, collate and save it \n",
    "for pull_year in  need_to_pull:\n",
    "    start = '{}:001:00:00:00'.format(pull_year)\n",
    "    stop = '{}:366:24:60:60'.format(pull_year)\n",
    "    print(start, stop)\n",
    "    \n",
    "    attitudes = ['AOATTQT1', 'AOATTQT2', 'AOATTQT3', 'AOATTQT4']\n",
    "    data = fetch.MSIDset( [msid_value, 'DP_PITCH'] + attitudes, start, stop, filter_bad = True)\n",
    "    \n",
    "    combined_dict, quat_vect_new = get_all_data(data[msid_value], data, data['DP_PITCH'])\n",
    "    save_file = file_format.format(msid_value, pull_year)\n",
    "    f = open(save_file, \"wb\")\n",
    "    pickle.dump(combined_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a lower limit if needed:285\n",
      "Enter an upper limit if needed:\n",
      "(964153, 6)\n",
      "           msid_times   msid_vals  pitch     raw_times    roll     yaw\n",
      "0 2018-01-01 00:00:32  295.708313  48.87  6.311521e+08  137.05 -111.88\n",
      "1 2018-01-01 00:01:05  295.708313  48.87  6.311521e+08  137.05 -111.87\n",
      "2 2018-01-01 00:01:38  295.708313  48.87  6.311522e+08  137.05 -111.87\n",
      "3 2018-01-01 00:02:11  295.708313  48.87  6.311522e+08  137.05 -111.87\n",
      "4 2018-01-01 00:02:43  295.708313  48.87  6.311522e+08  137.05 -111.87\n"
     ]
    }
   ],
   "source": [
    "train_year = 2018\n",
    "test_year = 2019\n",
    "test_msid_file = file_format.format(msid_value, test_year)\n",
    "train_msid_file = file_format.format(msid_value, train_year)\n",
    "\n",
    "train_dict = pd.read_pickle(train_msid_file)\n",
    "test_dict = pd.read_pickle(test_msid_file)\n",
    "\n",
    "#here we plot our graph and take out any obvious outliers \n",
    "fig, axs = plt.subplots(1, 1)\n",
    "train_set = pd.DataFrame(train_dict)\n",
    "test_set = pd.DataFrame(test_dict)\n",
    "#msid_set = pd.DataFrame({'times': data[msid_value].times, 'vals': data[msid_value].vals})\n",
    "axs.plot(train_set.msid_times, train_set.msid_vals, '.')\n",
    "plt.show()\n",
    "lower_limit = input(\"Enter a lower limit if needed:\")\n",
    "upper_limit = input(\"Enter an upper limit if needed:\")\n",
    "if (lower_limit.isdigit()):\n",
    "    lower_limit = int(lower_limit)\n",
    "    train_set = train_set[(train_set['msid_vals']>lower_limit)]\n",
    "if (upper_limit.isdigit()):\n",
    "    upper_limit = int(upper_limit)\n",
    "    train_set = train_set[(train_set['msid_vals']<upper_limit)]\n",
    "print (train_set.shape)\n",
    "print (train_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variables we will use \n",
    "cols = ['msid_times', 'msid_vals', 'pitch', 'roll','raw_times']\n",
    "#the positions we are using can also include yaw if wanted to\n",
    "pos = ['pitch', 'roll']\n",
    "n_features = 3 #change this to 4 if we're using yaw\n",
    "frames = 8\n",
    "spacing_int = 30\n",
    "percentage = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big df shape:  (964153, 3)\n",
      "    msid_vals(t-8)  pitch(t-8)  roll(t-8)  msid_vals(t-7)  pitch(t-7)  \\\n",
      "8         0.201863    0.016904   0.380694        0.201863    0.016904   \n",
      "9         0.201863    0.016904   0.380694        0.201863    0.016904   \n",
      "10        0.201863    0.016904   0.380694        0.201863    0.016904   \n",
      "11        0.201863    0.016904   0.380694        0.201863    0.016904   \n",
      "12        0.201863    0.016904   0.380694        0.201863    0.016904   \n",
      "\n",
      "    roll(t-7)  msid_vals(t-6)  pitch(t-6)  roll(t-6)  msid_vals(t-5)  \\\n",
      "8    0.380694        0.201863    0.016904   0.380694        0.201863   \n",
      "9    0.380694        0.201863    0.016904   0.380694        0.201863   \n",
      "10   0.380694        0.201863    0.016904   0.380694        0.201863   \n",
      "11   0.380694        0.201863    0.016904   0.380694        0.201863   \n",
      "12   0.380694        0.201863    0.016904   0.380694        0.201863   \n",
      "\n",
      "      ...     roll(t-3)  msid_vals(t-2)  pitch(t-2)  roll(t-2)  \\\n",
      "8     ...      0.380694        0.201863    0.016904   0.380694   \n",
      "9     ...      0.380694        0.201863    0.016904   0.380694   \n",
      "10    ...      0.380694        0.201863    0.016904   0.380694   \n",
      "11    ...      0.380694        0.201863    0.016904   0.380694   \n",
      "12    ...      0.380694        0.201863    0.016904   0.380694   \n",
      "\n",
      "    msid_vals(t-1)  pitch(t-1)  roll(t-1)  msid_vals(t)  pitch(t)   roll(t)  \n",
      "8         0.201863    0.016904   0.380694      0.201863  0.016904  0.380694  \n",
      "9         0.201863    0.016904   0.380694      0.201863  0.016904  0.380694  \n",
      "10        0.201863    0.016904   0.380694      0.201863  0.016904  0.380694  \n",
      "11        0.201863    0.016904   0.380694      0.201863  0.016980  0.380694  \n",
      "12        0.201863    0.016980   0.380694      0.201863  0.016980  0.380694  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "intv_times shape:  (32138,)\n",
      "    msid_vals(t-8)  pitch(t-8)  roll(t-8)  msid_vals(t-7)  pitch(t-7)  \\\n",
      "8         0.201863    0.016927   0.380694        0.201863    0.016980   \n",
      "9         0.201863    0.016980   0.380687        0.200742    0.016985   \n",
      "10        0.200742    0.016985   0.380696        0.195134    0.017033   \n",
      "11        0.195134    0.017033   0.380691        0.195134    0.017055   \n",
      "12        0.195134    0.017055   0.380690        0.195134    0.017073   \n",
      "\n",
      "    roll(t-7)  msid_vals(t-6)  pitch(t-6)  roll(t-6)  msid_vals(t-5)  \\\n",
      "8    0.380687        0.200742    0.016985   0.380696        0.195134   \n",
      "9    0.380696        0.195134    0.017033   0.380691        0.195134   \n",
      "10   0.380691        0.195134    0.017055   0.380690        0.195134   \n",
      "11   0.380690        0.195134    0.017073   0.380694        0.195134   \n",
      "12   0.380694        0.195134    0.017131   0.380692        0.195134   \n",
      "\n",
      "      ...     roll(t-3)  msid_vals(t-2)  pitch(t-2)  roll(t-2)  \\\n",
      "8     ...      0.380694        0.195134    0.017131   0.380692   \n",
      "9     ...      0.380692        0.195134    0.017131   0.380695   \n",
      "10    ...      0.380695        0.195134    0.017169   0.380692   \n",
      "11    ...      0.380692        0.189527    0.017206   0.380689   \n",
      "12    ...      0.380689        0.188405    0.017375   0.377959   \n",
      "\n",
      "    msid_vals(t-1)  pitch(t-1)  roll(t-1)  msid_vals(t)  pitch(t)   roll(t)  \n",
      "8         0.195134    0.017131   0.380695      0.195134  0.017169  0.380692  \n",
      "9         0.195134    0.017169   0.380692      0.189527  0.017206  0.380689  \n",
      "10        0.189527    0.017206   0.380689      0.188405  0.017375  0.377959  \n",
      "11        0.188405    0.017375   0.377959      0.188405  0.033517  0.268615  \n",
      "12        0.188405    0.033517   0.268615      0.188405  0.065082  0.160871  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "This is the shape of your averaged training set:  (32130, 25) (32138,)\n",
      "chunk_sizes: (left, time, right, time) (771316, 25) (771316,) (192829, 25) (192829,)\n",
      "chunk_sizes: (left, time, right, time) (25704, 25) (25704,) (6426, 25) (6426,)\n",
      "    msid_vals(t-8)  pitch(t-8)  roll(t-8)  msid_vals(t-7)  pitch(t-7)  \\\n",
      "8          0.54503    0.857822   0.801417         0.54503    0.858048   \n",
      "9          0.54503    0.858048   0.798694         0.54503    0.858350   \n",
      "10         0.54503    0.858350   0.795639         0.54503    0.858652   \n",
      "11         0.54503    0.858652   0.792194         0.54503    0.859030   \n",
      "12         0.54503    0.859030   0.788444         0.54503    0.859407   \n",
      "\n",
      "    roll(t-7)  msid_vals(t-6)  pitch(t-6)  roll(t-6)  msid_vals(t-5)  \\\n",
      "8    0.798694         0.54503    0.858350   0.795639         0.54503   \n",
      "9    0.795639         0.54503    0.858652   0.792194         0.54503   \n",
      "10   0.792194         0.54503    0.859030   0.788444         0.54503   \n",
      "11   0.788444         0.54503    0.859407   0.784306         0.54503   \n",
      "12   0.784306         0.54503    0.859784   0.779806         0.54503   \n",
      "\n",
      "      ...     roll(t-3)  msid_vals(t-2)  pitch(t-2)  roll(t-2)  \\\n",
      "8     ...      0.784306         0.54503    0.859784   0.779806   \n",
      "9     ...      0.779806         0.54503    0.860237   0.774972   \n",
      "10    ...      0.774972         0.54503    0.860690   0.769750   \n",
      "11    ...      0.769750         0.54503    0.861218   0.764139   \n",
      "12    ...      0.764139         0.54503    0.861746   0.758167   \n",
      "\n",
      "    msid_vals(t-1)  pitch(t-1)  roll(t-1)  msid_vals(t)  pitch(t)   roll(t)  \n",
      "8          0.54503    0.860237   0.774972       0.54503  0.860690  0.769750  \n",
      "9          0.54503    0.860690   0.769750       0.54503  0.861218  0.764139  \n",
      "10         0.54503    0.861218   0.764139       0.54503  0.861746  0.758167  \n",
      "11         0.54503    0.861746   0.758167       0.54503  0.862275  0.751833  \n",
      "12         0.54503    0.862275   0.751833       0.54503  0.862803  0.745306  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "This is the shape of your test set: (578212, 25) (578212,)\n",
      "This is your test data reshaped: [[0.5450305  0.85782205 0.80141667 0.5450305  0.85804845 0.79869444\n",
      "  0.5450305  0.85835031 0.79563889 0.5450305  0.85865218 0.79219444\n",
      "  0.5450305  0.85902951 0.78844444 0.5450305  0.85940684 0.78430556\n",
      "  0.5450305  0.85978417 0.77980556 0.5450305  0.86023696 0.77497222\n",
      "  0.5450305 ]]\n"
     ]
    }
   ],
   "source": [
    "# an LSTM model takes as a 3d tensor so we need to reshape our data to fit that\n",
    "# the shape is a 3d tensor with dimensions (batch_size, time_steps, features)\n",
    "np.random.seed(0)\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras import models, callbacks\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.engine import training_arrays\n",
    "\n",
    "def create_model(n_neurons, timesteps, data_dim, p_W, p_U, weight_decay, p_dense):\n",
    "    #dropout is used for uncertainty calculations\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(n_neurons, input_shape = (timesteps, data_dim),\n",
    "                   kernel_regularizer=l2(weight_decay), U_regularizer=l2(weight_decay),\n",
    "                   bias_regularizer=l2(weight_decay), dropout=p_W, recurrent_dropout=p_U))\n",
    "    model.add(Dropout(p_dense))\n",
    "    model.add(Dense(1,  kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay)))\n",
    "    optimiser = 'adam'\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimiser, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "#first we clean our training set and rows with null values\n",
    "train_clean_set, train_raw_time, train_time = dmf.clean_data(train_set, cols, pos)\n",
    "raw_msid_val = train_clean_set.drop(pos, axis = 1)\n",
    "#scale training data and return the scalers so we can use them to unscale\n",
    "scaler_all, scaler_msid, scaled_train = dmf.scale_training(train_clean_set, raw_msid_val)\n",
    "# shape data using our common function \n",
    "# this common function returns data in roll(t-8), pitch(t-8), val(t-8)... val(t) \n",
    "# drops pitch(t) and roll(t)\n",
    "shaped_train, begin_int = dmf.shaping_data(scaled_train, pos, frames)\n",
    "# take the shaped data and return an averaged version \n",
    "variables = pos + ['msid_vals']\n",
    "averaged_obs, train_time_avg = dmf.get_averaged_data(scaled_train, train_time, spacing_int, variables)\n",
    "shaped_train_avg, begin_int_avg = dmf.shaping_data(averaged_obs, pos, frames)\n",
    "print (\"This is the shape of your averaged training set: \", shaped_train_avg.shape, train_time_avg.shape)\n",
    "#\n",
    "# split training data that has already been shaped into training and validation\n",
    "shaped_train_full, train_time_full, shaped_val_full, val_time_full = dmf.split_shaped_data(shaped_train, train_time, percentage, begin_int)\n",
    "shaped_train_avg, train_time_avg, shaped_val_avg, val_time_avg = dmf.split_shaped_data(shaped_train_avg, train_time_avg, percentage, begin_int_avg)\n",
    "\n",
    "#\n",
    "# now clean, scale and shape the test data\n",
    "#\n",
    "test_clean_set, test_raw_time, test_time = dmf.clean_data(test_set, cols, pos)\n",
    "# using the same scaler as the train set to scale the test set\n",
    "scaled_test = scaler_all.transform(test_clean_set)\n",
    "scaled_test = pd.DataFrame(scaled_test, columns = test_clean_set.columns)\n",
    "shaped_test, begin_int_test = dmf.shaping_data(scaled_test, pos, frames)\n",
    "test_time = test_time[begin_int_test:]\n",
    "print (\"This is the shape of your test set:\", shaped_test.shape, test_time.shape)\n",
    "print (\"This is your test data reshaped:\", shaped_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval 1 (771316, 24)\n",
      "interval 2 (771316, 8, 3)\n",
      "interval 1 (25704, 24)\n",
      "interval 2 (25704, 8, 3)\n",
      "interval 1 (192829, 24)\n",
      "interval 2 (192829, 8, 3)\n",
      "interval 1 (578212, 24)\n",
      "interval 2 (578212, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch1/miniconda3/envs/ska3/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(8, input_shape=(8, 3), kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., dropout=0.05, recurrent_dropout=0.05, recurrent_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "# take shaped test, train and validation data and return inputs/outputs\n",
    "# split io reshapes data to be 3D tensor shape (samples, timesteps, features)\n",
    "# essentially whatev_X [[roll(t-8),pitch(t-8),val(t-8)]...[roll(t-1),pitch(t-1),val(t-1)]]\n",
    "# whatev_y is [val(t)]\n",
    "train_X_full, train_y_full = dmf.split_io(shaped_train_full, frames, n_features)\n",
    "train_X_avg, train_y_avg = dmf.split_io(shaped_train_avg, frames, n_features)\n",
    "validate_X, validate_y = dmf.split_io(shaped_val_full, frames, n_features)\n",
    "test_X, test_y = dmf.split_io(shaped_test, frames, n_features)\n",
    "train_X, train_y = train_X_avg, train_y_avg\n",
    "\n",
    "#send p_dense to 0 to ignore dropout\n",
    "p_W, p_U, p_dense, weight_decay, batch_size, n_neurons = 0.05, 0.05, 0.00, 1e-6, 512, 8\n",
    "epochs = 100\n",
    "#create model\n",
    "timesteps, data_dim = train_X.shape[1] , train_X.shape[2]\n",
    "checkpoint_path = 'weights_best_{}_yr{}_pW_{}_pU_{}_pdense{}'.format(msid_value,train_year, p_W, p_U, p_dense)\n",
    "model = create_model(n_neurons, timesteps, data_dim, p_W, p_U, weight_decay, p_dense)\n",
    "\n",
    "# checkpoint path to save weights\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath= checkpoint_path,\n",
    "                                         verbose = 0, save_best_only = True,\n",
    "                                         save_weights_only = True, mode = 'min')\n",
    "fit_time_begin = timeit.default_timer()\n",
    "history = model.fit(train_X, train_y,validation_data=(validate_X, validate_y),\n",
    "                    batch_size=batch_size, epochs=epochs, callbacks=[ checkpointer], shuffle = False , verbose = 0)\n",
    "fit_time = timeit.default_timer() - fit_time_begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_dashboard(plot_time, y_preds, y_actual, uncertainty, test_year, train_year, msid_value, optional_preds=None):\n",
    "    #err_top, err_bot = y_preds-uncertainty , y_preds+uncertainty\n",
    "\n",
    "    fig = plt.figure(figsize=(22.5, 15), constrained_layout=True)\n",
    "    gs = fig.add_gridspec(6,3)\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0:4,:-1])\n",
    "    ##########################\n",
    "    # Plotting Predicted vs Actual\n",
    "    # x axis is time, y axis is msid\n",
    "    ##########################\n",
    "    ax1.plot(plot_time, y_preds, '.' , markersize = 1, label = 'predicted', color = 'tab:orange')\n",
    "    if (optional_preds is not None):\n",
    "        ax1.plot(plot_time, optional_preds, '.', markersize = 1, label = 'chain prediction', color = 'blue')\n",
    "    ax1.plot(plot_time, y_actual, '.', markersize = 1, label = 'actual', color = 'black')\n",
    "    #ax1.fill_between(plot_time.values, err_top, err_bot, label = 'uncertainty', color = 'grey')\n",
    "    ax1.legend(markerscale=12.0)\n",
    "    ax1.set_xticklabels(plot_time, rotation=45)\n",
    "    ax1.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y:%j\"))\n",
    "    ax1.set_title('Predicted vs Actual {} {}'.format(msid_value, train_year))\n",
    "\n",
    "\n",
    "    #########################\n",
    "    # Plotting Model Error which is just actual y value minus test y value\n",
    "    # x axis is time, y axis is error \n",
    "    #########################\n",
    "    ax2 = fig.add_subplot(gs[4,:-1])\n",
    "    errors =  y_actual - y_preds\n",
    "    #dist_top = err_top - y_actual\n",
    "    #dist_bot = err_bot - y_actual\n",
    "    #one_perc = np.quantile(errors, 0.01)\n",
    "    #nn_perc = np.quantile(errors, .99)\n",
    "    scale = np.ptp(y_actual)/2.0\n",
    "    ax2.plot(plot_time, errors, color = 'green')\n",
    "    #ax2.plot(plot_time, dist_top, color = 'gray')\n",
    "    #ax2.plot(plot_time, dist_bot, color = 'gray')\n",
    "    ax2.set_ylim(-scale, scale)\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.set_xticklabels(plot_time, rotation=45)\n",
    "    ax2.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y:%j\"))\n",
    "\n",
    "    ax2.set_title('Model Error (Actual - Test) {} {}'.format(msid_value, train_year))\n",
    "\n",
    "    #########################\n",
    "    # Plotting Error by Temperature\n",
    "    # \n",
    "    #########################\n",
    "    ax3 = fig.add_subplot(gs[0:4,2])\n",
    "    ax3.plot(errors, y_actual, '.', color = 'green')\n",
    "    ax3.set_xlim(-scale, scale)\n",
    "    ax3.set_ylim(ax1.get_ylim())\n",
    "    ax3.set_title('Actual vs. Model Error {} {}'.format(msid_value, train_year))\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[4, 2])\n",
    "    ax4.hist(errors, bins = 25, density=True, color= 'green')\n",
    "    ax4.set_xlim(ax3.get_xlim())\n",
    "    ax4.set_title(\"Error Distribution {} {}\".format(msid_value, train_year))\n",
    "\n",
    "    #plt.savefig('{}_test{}_train{}_full_dash.png'.format(msid_value, test_year, train_year))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_X)\n",
    "scaled_predictions = scaler_msid.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty = []\n",
    "y_actual = scaler_msid.inverse_transform(np.atleast_2d(test_y))\n",
    "plot_dashboard(test_time, np.squeeze(scaled_predictions), np.squeeze(y_actual), uncertainty, test_year, train_year, msid_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
